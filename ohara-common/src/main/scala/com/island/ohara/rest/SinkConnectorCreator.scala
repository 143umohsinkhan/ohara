package com.island.ohara.rest
import java.util.Objects

import com.island.ohara.config.{OharaConfig, OharaJson}

import scala.collection.mutable

/**
  * Used to config and run the sink connector.
  */
abstract class SinkConnectorCreator {
  protected var name: String = null
  protected var clzName: String = null
  protected var topicNames: Seq[String] = null
  protected var taskMax: Int = -1
  protected var config: Map[String, String] = null
  protected var _disableConverter: Boolean = false

  /**
    * config the converter be org.apache.kafka.connect.converters.ByteArrayConverter. It is useful if the data in topic
    * your connector want to take is byte array and is generated by kafka producer. For example, the source is RowProducer,
    * and the target is RowSinkConnector.
    *
    * @return this one
    */
  def disableConverter(): this.type = {
    this._disableConverter = true
    this
  }

  /**
    * set the connector name. It should be a unique name.
    * @param name connector name
    * @return this one
    */
  def name(name: String): this.type = {
    this.name = name
    this
  }

  /**
    * set the connector class. The class must be loaded in class loader otherwise it will fail to create the connector.
    * @param clz connector class
    * @return this one
    */
  def connectorClass(clzName: String): this.type = {
    this.clzName = clzName
    this
  }

  /**
    * set the topic in which you have interest.
    * @param topicName topic
    * @return this one
    */
  def topic(topicName: String): this.type = topics(Seq(topicName))

  /**
    * set the topics in which you have interest.
    * @param topicNames topics
    * @return this one
    */
  def topics(topicNames: Seq[String]): this.type = {
    this.topicNames = topicNames
    this
  }

  /**
    * the max number of sink task you want to create
    * @param taskMax max number of sink task
    * @return this one
    */
  def taskNumber(taskMax: Int): this.type = {
    this.taskMax = taskMax
    this
  }

  /**
    * extra config passed to sink connector. This config is optional.
    * @param config config
    * @return this one
    */
  def config(config: Map[String, String]): this.type = {
    this.config = config
    this
  }

  /**
    * send the request to create the sink connector.
    * @return this one
    */
  def run(): RestResponse = {
    checkArgument()
    val request = OharaConfig()
    val connectConfig = new mutable.HashMap[String, String]
    if (config != null) connectConfig ++= config
    request.set("name", name)
    connectConfig.put("connector.class", clzName)
    connectConfig.put("topics", topicNames.mkString(","))
    connectConfig.put("tasks.max", taskMax.toString)
    if (_disableConverter) {
      connectConfig.put("key.converter", "org.apache.kafka.connect.converters.ByteArrayConverter")
      connectConfig.put("value.converter", "org.apache.kafka.connect.converters.ByteArrayConverter")
    }
    request.set("config", connectConfig.toMap)
    send("connectors", OharaJson(request.toJson.toString))
  }

  /**
    * send the request to kafka worker
    * @param cmd related path
    * @param body body
    * @return response
    */
  protected def send(cmd: String, body: OharaJson): RestResponse

  private[this] def checkArgument(): Unit = {
    Objects.requireNonNull(name)
    Objects.requireNonNull(clzName)
    Objects.requireNonNull(topicNames)
    if (topicNames.isEmpty) throw new IllegalArgumentException(s"You must specify 1+ topic names")
    if (taskMax <= 0) throw new IllegalArgumentException(s"taskMax should be bigger than zero, current:$taskMax")
  }
}

object SinkConnectorCreator {

  def apply(restClient: BoundRestClient): SinkConnectorCreator = (cmd: String, body: OharaJson) =>
    restClient.post(cmd, body)
}
